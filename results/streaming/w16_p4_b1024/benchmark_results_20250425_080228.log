DATASET STREAMING BENCHMARKS
Started at: 2025-04-25 08:07:08
Configuration: batch_size=1024, num_workers=16, prefetch_factor=4



========== WebDataset ==========
Seed set to 42
/home/ec2-user/benchmark-dataloader/.venv/lib/python3.13/site-packages/webdataset/compat.py:389: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number
  warnings.warn(
Seed set to 42
Using remote path: s3://datology-assets-dev/users/haoli/shards/webdataset
Using remote path: s3://datology-assets-dev/users/haoli/shards/webdataset
Listing objects...
Found 23 objects in S3
Found 23 train tar files matching pattern 'benchmark-train-'
Cache directory: /home/ec2-user/benchmark-dataloader/stream/cache/webdataset_benchmark
Using cache directory: /home/ec2-user/benchmark-dataloader/stream/cache/webdataset_benchmark
Using 16 worker threads for data loading
Starting benchmark with batch size 1024

Epoch 1/2: 0it [00:00, ?it/s]
Epoch 1/2: 1it [00:07,  7.34s/it]
Epoch 1/2: 17it [00:12,  1.37it/s]
Epoch 1/2: 33it [00:17,  1.93it/s]
Epoch 1/2: 49it [00:22,  2.14it/s]
Epoch 1/2: 65it [00:25,  2.53it/s]
Epoch 1/2: 81it [00:31,  2.56it/s]
Epoch 1/2: 92it [00:33,  2.76it/s]
Time to first batch: 7.3442s
Epoch 1: Processed 88514 samples in 33.30s (2658.24 images/sec)

Epoch 2/2: 0it [00:00, ?it/s]
Epoch 2/2: 1it [00:05,  5.50s/it]
Epoch 2/2: 17it [00:10,  1.64it/s]
Epoch 2/2: 33it [00:15,  2.15it/s]
Epoch 2/2: 49it [00:19,  2.56it/s]
Epoch 2/2: 65it [00:22,  2.94it/s]
Epoch 2/2: 81it [00:27,  2.92it/s]
Epoch 2/2: 92it [00:29,  3.11it/s]
Epoch 2: Processed 88514 samples in 29.63s (2987.78 images/sec)

Benchmark Summary:
  Total samples: 177028
  Wall time: 62.92s
  Throughput: 2987.78 images/sec
  Time to first batch: 7.3442s
Benchmark complete
Cleaning up cache directory: /home/ec2-user/benchmark-dataloader/stream/cache/webdataset_benchmark


========== MosaicML MDS ==========
Seed set to 42
Seed set to 42
Using remote path: s3://datology-assets-dev/users/haoli/shards/mds
Cache directory: /home/ec2-user/benchmark-dataloader/stream/cache/mds_benchmark
Using cache directory: /home/ec2-user/benchmark-dataloader/stream/cache/mds_benchmark
Using 16 worker threads for data loading
Starting benchmark with batch size 1024

Epoch 1/2:   0%|          | 0/87 [00:00<?, ?it/s]
Epoch 1/2:   1%|          | 1/87 [00:09<14:03,  9.81s/it]
Epoch 1/2:  20%|█▉        | 17/87 [00:14<00:58,  1.20it/s]
Epoch 1/2:  38%|███▊      | 33/87 [00:18<00:29,  1.80it/s]
Epoch 1/2:  56%|█████▋    | 49/87 [00:22<00:17,  2.17it/s]
Epoch 1/2:  75%|███████▍  | 65/87 [00:26<00:08,  2.45it/s]
Epoch 1/2:  93%|█████████▎| 81/87 [00:29<00:02,  2.79it/s]
Epoch 1/2: 100%|██████████| 87/87 [00:29<00:00,  2.97it/s]
Time to first batch: 9.8106s
Epoch 1: Processed 88514 samples in 29.30s (3021.20 images/sec)

Epoch 2/2:   0%|          | 0/87 [00:00<?, ?it/s]
Epoch 2/2:   1%|          | 1/87 [00:04<06:58,  4.86s/it]
Epoch 2/2:  20%|█▉        | 17/87 [00:09<00:37,  1.87it/s]
Epoch 2/2:  38%|███▊      | 33/87 [00:13<00:21,  2.50it/s]
Epoch 2/2:  56%|█████▋    | 49/87 [00:17<00:13,  2.82it/s]
Epoch 2/2:  75%|███████▍  | 65/87 [00:21<00:07,  3.04it/s]
Epoch 2/2:  93%|█████████▎| 81/87 [00:24<00:01,  3.37it/s]
Epoch 2/2: 100%|██████████| 87/87 [00:24<00:00,  3.57it/s]
Epoch 2: Processed 88514 samples in 24.40s (3627.45 images/sec)

Benchmark Summary:
  Total samples: 177028
  Wall time: 53.70s
  Throughput: 3627.45 images/sec
  Time to first batch: 9.8106s
Benchmark complete
Cleaning up cache directory: /home/ec2-user/benchmark-dataloader/stream/cache/mds_benchmark


========== LitData ==========
Seed set to 42
/home/ec2-user/benchmark-dataloader/stream/lightning_data.py:77: A newer version of litdata is available (0.2.45). Please consider upgrading with `pip install -U litdata`. Not all functionalities of the platform can be guaranteed to work with the current version.
Seed set to 42
Using S3 path from environment...
Using remote path: s3://datology-assets-dev/users/haoli/shards/litdata
Using remote path: s3://datology-assets-dev/users/haoli/shards/litdata
Cache directory: /home/ec2-user/benchmark-dataloader/stream/cache/litdata_benchmark
Using cache directory: /home/ec2-user/benchmark-dataloader/stream/cache/litdata_benchmark
Using 16 worker threads for data loading
Starting benchmark with batch size 1024

Epoch 1/2:   0%|          | 0/87 [00:00<?, ?it/s]
Epoch 1/2:   1%|          | 1/87 [00:04<06:34,  4.58s/it]
Epoch 1/2:  16%|█▌        | 14/87 [00:05<00:29,  2.49it/s]
Epoch 1/2:  31%|███       | 27/87 [00:09<00:20,  2.89it/s]
Epoch 1/2:  46%|████▌     | 40/87 [00:13<00:15,  2.98it/s]
Epoch 1/2:  61%|██████    | 53/87 [00:17<00:11,  3.02it/s]
Epoch 1/2:  76%|███████▌  | 66/87 [00:21<00:06,  3.10it/s]
Epoch 1/2:  93%|█████████▎| 81/87 [00:23<00:01,  3.38it/s]
Epoch 1/2: 100%|██████████| 87/87 [00:24<00:00,  3.59it/s]
Time to first batch: 4.5905s
Epoch 1: Processed 88514 samples in 24.24s (3651.92 images/sec)

Epoch 2/2:   0%|          | 0/87 [00:00<?, ?it/s]
Epoch 2/2:   1%|          | 1/87 [00:04<06:21,  4.44s/it]
Epoch 2/2:  20%|█▉        | 17/87 [00:08<00:35,  1.95it/s]
Epoch 2/2:  38%|███▊      | 33/87 [00:13<00:21,  2.53it/s]
Epoch 2/2:  56%|█████▋    | 49/87 [00:17<00:13,  2.85it/s]
Epoch 2/2:  75%|███████▍  | 65/87 [00:21<00:07,  3.06it/s]
Epoch 2/2:  93%|█████████▎| 81/87 [00:23<00:01,  3.41it/s]
Epoch 2/2: 100%|██████████| 87/87 [00:24<00:00,  3.62it/s]
Epoch 2: Processed 88514 samples in 24.03s (3683.61 images/sec)

Benchmark Summary:
  Total samples: 177028
  Wall time: 48.27s
  Throughput: 3683.61 images/sec
  Time to first batch: 4.5905s
Benchmark complete
Benchmark complete
Cleaning up cache directory: /home/ec2-user/benchmark-dataloader/stream/cache/litdata_benchmark


========== Energon ==========
Seed set to 42
/home/ec2-user/benchmark-dataloader/.venv/lib/python3.13/site-packages/megatron/energon/loader.py:89: FutureWarning: Passing a worker_config to get_loader() is deprecated and will have no effect.
  warn_deprecated(
Using MSC_CONFIG: /home/ec2-user/benchmark-dataloader/stream/.msc_config.yaml
Using remote path: s3://datology-assets-dev/users/haoli/shards/energon
rank=0, worker=0: sample_range=[0, 5533] in 55 slices, sum(count)=5533: indexes=[0, 100, 201 ...<50> 5331, 5432, 5533] slices=[benchmark-train-000000.tar[0(start), 100], benchmark-train-000000.tar[100, 201], benchmark-train-000000.tar[201, 301] ...<50> benchmark-train-000001.tar[1410, 1511], benchmark-train-000001.tar[1511, 1612], benchmark-train-000001.tar[1612, 1713]]
rank=0, worker=1: sample_range=[5533, 11065] in 55 slices, sum(count)=5532: indexes=[5533, 5632, 5732 ...<50> 10862, 10963, 11065] slices=[benchmark-train-000001.tar[1713, 1812], benchmark-train-000001.tar[1812, 1912], benchmark-train-000001.tar[1912, 2012] ...<50> benchmark-train-000002.tar[3034, 3135], benchmark-train-000002.tar[3135, 3236], benchmark-train-000002.tar[3236, 3338]]
rank=0, worker=2: sample_range=[11065, 16597] in 55 slices, sum(count)=5532: indexes=[11065, 11174, 11283 ...<50> 16404, 16500, 16597] slices=[benchmark-train-000002.tar[3338, 3447], benchmark-train-000002.tar[3447, 3556], benchmark-train-000002.tar[3556, 3665] ...<50> benchmark-train-000004.tar[768, 864], benchmark-train-000004.tar[864, 960], benchmark-train-000004.tar[960, 1057]]
rank=0, worker=3: sample_range=[16597, 22129] in 56 slices, sum(count)=5532: indexes=[16597, 16695, 16793 ...<51> 21930, 22029, 22129] slices=[benchmark-train-000004.tar[1057, 1155], benchmark-train-000004.tar[1155, 1253], benchmark-train-000004.tar[1253, 1351] ...<51> benchmark-train-000005.tar[2483, 2583], benchmark-train-000005.tar[2583, 2682], benchmark-train-000005.tar[2682, 2782]]
rank=0, worker=4: sample_range=[22129, 27661] in 56 slices, sum(count)=5532: indexes=[22129, 22228, 22328 ...<51> 27468, 27564, 27661] slices=[benchmark-train-000005.tar[2782, 2881], benchmark-train-000005.tar[2881, 2981], benchmark-train-000005.tar[2981, 3080] ...<51> benchmark-train-000007.tar[385, 482], benchmark-train-000007.tar[482, 578], benchmark-train-000007.tar[578, 675]]
rank=0, worker=5: sample_range=[27661, 33193] in 56 slices, sum(count)=5532: indexes=[27661, 27760, 27859 ...<51> 32996, 33094, 33193] slices=[benchmark-train-000007.tar[675, 774], benchmark-train-000007.tar[774, 873], benchmark-train-000007.tar[873, 972] ...<51> benchmark-train-000008.tar[2067, 2166], benchmark-train-000008.tar[2166, 2264], benchmark-train-000008.tar[2264, 2363]]
rank=0, worker=6: sample_range=[33193, 38725] in 56 slices, sum(count)=5532: indexes=[33193, 33292, 33391 ...<51> 38556, 38640, 38725] slices=[benchmark-train-000008.tar[2363, 2462], benchmark-train-000008.tar[2462, 2561], benchmark-train-000008.tar[2561, 2660] ...<51> benchmark-train-000009.tar[3776, 3876(end)], benchmark-train-000010.tar[0(start), 84], benchmark-train-000010.tar[84, 169]]
rank=0, worker=7: sample_range=[38725, 44257] in 55 slices, sum(count)=5532: indexes=[38725, 38826, 38927 ...<50> 44057, 44157, 44257] slices=[benchmark-train-000010.tar[169, 270], benchmark-train-000010.tar[270, 371], benchmark-train-000010.tar[371, 472] ...<50> benchmark-train-000011.tar[1493, 1592], benchmark-train-000011.tar[1592, 1692], benchmark-train-000011.tar[1692, 1792]]
rank=0, worker=8: sample_range=[44257, 49790] in 55 slices, sum(count)=5533: indexes=[44257, 44356, 44456 ...<50> 49588, 49689, 49790] slices=[benchmark-train-000011.tar[1792, 1891], benchmark-train-000011.tar[1891, 1991], benchmark-train-000011.tar[1991, 2091] ...<50> benchmark-train-000012.tar[3231, 3332], benchmark-train-000012.tar[3332, 3433], benchmark-train-000012.tar[3433, 3534]]
rank=0, worker=9: sample_range=[49790, 55322] in 56 slices, sum(count)=5532: indexes=[49790, 49894, 49998 ...<51> 55128, 55225, 55322] slices=[benchmark-train-000012.tar[3534, 3638], benchmark-train-000012.tar[3638, 3742], benchmark-train-000012.tar[3742, 3846(end)] ...<51> benchmark-train-000014.tar[1066, 1163], benchmark-train-000014.tar[1163, 1260], benchmark-train-000014.tar[1260, 1357]]
rank=0, worker=10: sample_range=[55322, 60854] in 55 slices, sum(count)=5532: indexes=[55322, 55421, 55521 ...<50> 60651, 60752, 60854] slices=[benchmark-train-000014.tar[1357, 1456], benchmark-train-000014.tar[1456, 1556], benchmark-train-000014.tar[1556, 1655] ...<50> benchmark-train-000015.tar[2736, 2838], benchmark-train-000015.tar[2838, 2939], benchmark-train-000015.tar[2939, 3041]]
rank=0, worker=11: sample_range=[60854, 66386] in 55 slices, sum(count)=5532: indexes=[60854, 60956, 61059 ...<50> 66180, 66283, 66386] slices=[benchmark-train-000015.tar[3041, 3143], benchmark-train-000015.tar[3143, 3246], benchmark-train-000015.tar[3246, 3349] ...<50> benchmark-train-000017.tar[410, 512], benchmark-train-000017.tar[512, 615], benchmark-train-000017.tar[615, 718]]
rank=0, worker=12: sample_range=[66386, 71918] in 55 slices, sum(count)=5532: indexes=[66386, 66487, 66588 ...<50> 71718, 71818, 71918] slices=[benchmark-train-000017.tar[718, 819], benchmark-train-000017.tar[819, 920], benchmark-train-000017.tar[920, 1021] ...<50> benchmark-train-000018.tar[1995, 2095], benchmark-train-000018.tar[2095, 2195], benchmark-train-000018.tar[2195, 2295]]
rank=0, worker=13: sample_range=[71918, 77450] in 55 slices, sum(count)=5532: indexes=[71918, 72018, 72118 ...<50> 77254, 77355, 77450] slices=[benchmark-train-000018.tar[2295, 2395], benchmark-train-000018.tar[2395, 2495], benchmark-train-000018.tar[2495, 2596] ...<50> benchmark-train-000019.tar[3628, 3729], benchmark-train-000019.tar[3729, 3830(end)], benchmark-train-000020.tar[0(start), 95]]
rank=0, worker=14: sample_range=[77450, 82982] in 56 slices, sum(count)=5532: indexes=[77450, 77549, 77648 ...<51> 82785, 82883, 82982] slices=[benchmark-train-000020.tar[95, 194], benchmark-train-000020.tar[194, 293], benchmark-train-000020.tar[293, 392] ...<51> benchmark-train-000021.tar[1471, 1569], benchmark-train-000021.tar[1569, 1667], benchmark-train-000021.tar[1667, 1766]]
rank=0, worker=15: sample_range=[82982, 88514] in 55 slices, sum(count)=5532: indexes=[82982, 83082, 83183 ...<50> 88313, 88413, 88514] slices=[benchmark-train-000021.tar[1766, 1866], benchmark-train-000021.tar[1866, 1967], benchmark-train-000021.tar[1967, 2068] ...<50> benchmark-train-000022.tar[3114, 3215], benchmark-train-000022.tar[3215, 3315], benchmark-train-000022.tar[3315, 3416(end)]]
Starting benchmark with batch size 1024

Epoch 1/2:   0%|          | 0/87 [00:00<?, ?it/s]
Epoch 1/2:   1%|          | 1/87 [00:14<20:24, 14.24s/it]
Epoch 1/2:   6%|▌         | 5/87 [00:16<04:38,  3.39s/it]
Epoch 1/2:  20%|█▉        | 17/87 [00:21<01:29,  1.27s/it]
Epoch 1/2:  33%|███▎      | 29/87 [00:25<00:50,  1.14it/s]
Epoch 1/2:  47%|████▋     | 41/87 [00:32<00:36,  1.27it/s]
Epoch 1/2:  61%|██████    | 53/87 [00:40<00:25,  1.31it/s]
Epoch 1/2:  75%|███████▍  | 65/87 [00:43<00:14,  1.51it/s]
Epoch 1/2:  89%|████████▊ | 77/87 [00:46<00:06,  1.66it/s]
Epoch 1/2: 100%|██████████| 87/87 [00:50<00:00,  1.71it/s]
Time to first batch: 14.2378s
Epoch 1: Processed 89088 samples in 50.97s (1747.70 images/sec)

Epoch 2/2:   0%|          | 0/87 [00:00<?, ?it/s]
Epoch 2/2:   1%|          | 1/87 [00:08<11:39,  8.13s/it]
Epoch 2/2:   7%|▋         | 6/87 [00:09<02:04,  1.53s/it]
Epoch 2/2:  20%|█▉        | 17/87 [00:14<01:01,  1.14it/s]
Epoch 2/2:  32%|███▏      | 28/87 [00:16<00:33,  1.74it/s]
Epoch 2/2:  45%|████▍     | 39/87 [00:24<00:29,  1.61it/s]
Epoch 2/2:  57%|█████▋    | 50/87 [00:30<00:22,  1.66it/s]
Epoch 2/2:  70%|███████   | 61/87 [00:31<00:13,  1.92it/s]
Epoch 2/2:  83%|████████▎ | 72/87 [00:38<00:08,  1.87it/s]
Epoch 2/2:  95%|█████████▌| 83/87 [00:42<00:02,  1.96it/s]
Epoch 2/2: 100%|██████████| 87/87 [00:42<00:00,  2.04it/s]
Epoch 2: Processed 89088 samples in 42.59s (2091.97 images/sec)

Benchmark Summary:
  Total samples: 178176
  Wall time: 93.56s
  Throughput: 2091.97 images/sec
  Time to first batch: 14.2378s
Benchmark complete
